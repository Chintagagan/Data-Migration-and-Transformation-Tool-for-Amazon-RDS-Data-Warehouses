{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4ef42-a435-4cb8-865c-7d7f20581a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests boto3 pandas sqlalchemy psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69bace-4f35-4fdf-a55b-b6bd81941e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "local_zip_file = r\"ZIP FILE LOCTION\"  # Path to the downloaded ZIP file\n",
    "extract_folder = r\"EXTRACTED FOLDER PATH\"     # Folder to extract files into\n",
    "\n",
    "# Create extraction folder if it doesn't exist\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "# Unzip the downloaded file\n",
    "def unzip_file(zip_file_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(f\"Extracted {zip_file_path} to {extract_to}\")\n",
    "\n",
    "# Extract the ZIP file\n",
    "unzip_file(local_zip_file, extract_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23855264-dff3-4329-8567-8969fa3c8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Configure your S3 client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='Acess key ID',\n",
    "    aws_secret_access_key='Secret Access key',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "# Local file path and S3 bucket details\n",
    "local_file_path = r\"Path to file\"\n",
    "bucket_name = 'Bucket_name'\n",
    "s3_file_key = 'Path to file'  # Change 'folder-name' as needed\n",
    "\n",
    "# Upload the file\n",
    "try:\n",
    "    s3.upload_file(local_file_path, bucket_name, s3_file_key)\n",
    "    print(f\"File uploaded successfully to {bucket_name}/{s3_file_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading file: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1960d7-be2e-4fd3-b30e-7476b67e758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SQLAlchemy pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c40a4-6d1e-4d60-9724-5b1f0d7071df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database credentials and connection information\n",
    "db_user = 'admin'       # RDS database username\n",
    "db_password = 'PASSWORD'   # RDS database password\n",
    "db_host = 'Endpoint link'    # RDS endpoint\n",
    "db_port = '3306'                # RDS port, default is 3306 for MySQL\n",
    "db_name = 'Database name'  # Name of your RDS database\n",
    "\n",
    "# Create the connection string for the RDS instance\n",
    "connection_string = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        # If connection is successful, print message\n",
    "        print(\"Connection to the database was successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Error connecting to the database:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074aaf8-a781-4d8a-a9a4-efe4759ad494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pymysql\n",
    "import json\n",
    "\n",
    "# AWS and DB configurations\n",
    "s3_bucket = 'Bucket_Name'\n",
    "s3_key = 'File to path'\n",
    "db_host = 'Endpoint link'\n",
    "db_user = 'admin'\n",
    "db_password = 'PASSWORD'\n",
    "db_name = 'TEST'\n",
    "\n",
    "# Connect to S3\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.get_object(Bucket=s3_bucket, Key=s3_key)\n",
    "json_content = response['Body'].read().decode('utf-8')\n",
    "\n",
    "# Parse JSON content\n",
    "data = json.loads(json_content)\n",
    "\n",
    "# Connect to RDS\n",
    "connection = pymysql.connect(\n",
    "    host=db_host,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    database=db_name\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Insert JSON data into the table\n",
    "sql = \"INSERT INTO json_data (data) VALUES (%s)\"\n",
    "for record in data:\n",
    "    cursor.execute(sql, (json.dumps(record),))\n",
    "\n",
    "# Commit and close connection\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"JSON data uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a72a7c-a79c-48b8-8b9e-f97f4b61ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pymysql\n",
    "import json\n",
    "\n",
    "# AWS and DB configurations\n",
    "s3_bucket = 'Buckey_name'\n",
    "s3_key = 'Path to file'\n",
    "db_host = 'Endpoint link'\n",
    "db_user = 'admin'\n",
    "db_password = 'PASSWORD'\n",
    "db_name = 'DATABASE NAME'\n",
    "\n",
    "# Connect to S3\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.get_object(Bucket=s3_bucket, Key=s3_key)\n",
    "json_content = response['Body'].read().decode('utf-8')\n",
    "\n",
    "# Parse JSON content\n",
    "data = json.loads(json_content)\n",
    "\n",
    "# Connect to RDS\n",
    "connection = pymysql.connect(\n",
    "    host=db_host,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    database=db_name\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "# Extract and insert data\n",
    "cik = data['cik']\n",
    "entity_name = data['entityName']\n",
    "shares = data['facts']['dei']['EntityCommonStockSharesOutstanding']['units']['shares']\n",
    "\n",
    "for entry in shares:\n",
    "    end_date = entry['end']\n",
    "    value = entry['val']\n",
    "    sql = \"INSERT INTO extracted_data (cik, entityName, end_date, value) VALUES (%s, %s, %s, %s)\"\n",
    "    cursor.execute(sql, (cik, entity_name, end_date, value))\n",
    "\n",
    "# Commit changes and close connection\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Data inserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11134c-92bc-43e1-88e2-0ebb13b907fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c362459-150c-4e85-a823-2a3ba65a4657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a6951-40b3-476b-9620-537de2eba260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7e1d4-b752-4e53-ae30-e9df74a029b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a148e-36d5-482d-8a9a-2bdf53ffc2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
